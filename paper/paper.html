<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.489">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Josiah Parry">
<meta name="author" content="Robin Lovelace">

<title>ANIME</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="paper_files/libs/clipboard/clipboard.min.js"></script>
<script src="paper_files/libs/quarto-html/quarto.js"></script>
<script src="paper_files/libs/quarto-html/popper.min.js"></script>
<script src="paper_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="paper_files/libs/quarto-html/anchor.min.js"></script>
<link href="paper_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="paper_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="paper_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="paper_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="paper_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">ANIME</h1>
<p class="subtitle lead">Approximate Network Matching and Integration Enrichment</p>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Authors</div>
  <div class="quarto-title-meta-heading">Affiliations</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Josiah Parry <a href="https://orcid.org/0000-0001-9910-865X" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Environmental Systems Research Institute, Redlands, CA, USA
          </p>
      </div>
      <div class="quarto-title-meta-contents">
    <p class="author">Robin Lovelace <a href="https://orcid.org/0000-0001-5679-6536" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Leeds Institute for Transport Studies, University of Leeds, UK
          </p>
      </div>
    </div>

<div class="quarto-title-meta">

      
  
    
  </div>
  


</header>


<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<p>Reconciling topologically different linestrings is a fundamental challenge in spatial data science, particularly when attempting to integrate network datasets from disparate sources. Existing methods often struggle with the absence of join keys and the need for wholesale joining of attributes, hindering effective data integration and analysis. In this paper, we propose a novel algorithm for matching two sets of linestrings, implemented in an open-source Rust library with bindings to R and Python. Our algorithm addresses the challenge by identifying topologically similar linestrings and estimating the shared length between each pair of matched linestrings. By leveraging R* spatial indices and angle-based matching criteria, our approach effectively reconciles linestrings with varying topologies. We demonstrate the utility of our algorithm through applications in spatial data analysis, including joins, weighted aggregations, and network subset identification based on shared characteristics. The proposed algorithm offers a robust solution for reconciling linestrings in spatial datasets, with implications for various domains in spatial data science.</p>
<!--

- A common issue in spatial data science is the reconciliation of two sets of linestrings. 
- linestrings may represent the same phenomenon but be topologically different
- joining data between these road networks is problematic for many reasons
- often there may be no join key present
  - if there is a join key, there remains an issue of wholesale joining of attributes
    - attributes of a linestring are intended be associated with that linestring, not another
    - we need to do a join and provide a weight for future calculations 
- in this paper we introduce a new algorithm to match two sets of linestrings
- it is implemented in an open source rust library with bindings to R and Python
-->
</section>
<section id="problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="problem-statement">Problem Statement</h2>
<p><strong>Overarching Idea</strong>:</p>
<ul>
<li>use the approximate network matching to create a list of <em>strong</em> candidate matches with a known shared overlap amount.</li>
<li>The result of the approximate network match can be taken and utilized for ‘vertical conflation’ using many different approaches</li>
<li>in this paper we introduce a method of spatial interpolation of linear features</li>
</ul>
<blockquote class="blockquote">
<p>“Due to the complexity and limitations of existing methods, planners and analysts often have to employ a heavily manual conflation process, which is time‐consuming and often prohibitively expensive.” Lei, Ting; Lei, Zhen (2019).</p>
</blockquote>
<ul>
<li><p>datasets are derived from remotely sensed imagery (samal et al., 2004)</p>
<ul>
<li>this is happening on a much larger scale for example google building footprints (https://sites.research.google/open-buildings/)</li>
<li>features may not always be complete or entirely accurate but can be used to supplement missing data or address changes in a dataset</li>
</ul></li>
<li><p>matching generalized to more detailed geometry is tough and an unsolved problem , see “LoD” mentions (Ick-Hoi Kim, Chen-Chieh Feng &amp; Yi-Chen Wang), (Mustiere &amp; Devogele, 2008), (Zhang 2009)</p></li>
<li><p>In a road database, several objects may represent different parts of the same real-world road, e.g., each lane in a highway could be represented by a different object,(Zhang 2009)</p></li>
<li><p>some features can be have no corresponding features or many</p></li>
<li><p>missing join keys between disparate datasets or missing semantic information requires a geometric only approach (Ick-Hoi Kim, Chen-Chieh Feng &amp; Yi-Chen Wang, )</p></li>
</ul>
<blockquote class="blockquote">
<p>“a simple overlay of the sources would not automatically reveal correspondence.” (Samal et al, 2004)</p>
</blockquote>
</section>
<section id="definitions" class="level2">
<h2 class="anchored" data-anchor-id="definitions">Definitions</h2>
<p>The purpose of this section is to provide clear and concise definitions of terminologies used in the description of this algorithm.</p>
<p>We will use the simple feature access standards definitions of geometric primitives for the sake of consistency. In our algorithm we make extensive use of <strong>Line</strong> and <strong>LineString</strong> geometric primitives. A Line is defined by two <strong>Point</strong>s that are (x, y) coordinate pairs. A LineString is composed of 2 or more Points and “each consecutive pair of Points defines a Line segment.” (<span class="citation" data-cites="sfa">(<a href="#ref-sfa" role="doc-biblioref"><strong>sfa?</strong></a>)</span> FIXME cite). Each LineString is referred to as a <strong>feature</strong>. An array of features is referred to as a <strong>FeatureCollection</strong> (<span class="citation" data-cites="geojson_spec">(<a href="#ref-geojson_spec" role="doc-biblioref"><strong>geojson_spec?</strong></a>)</span>).</p>
<p>The objective of this algorithm is to identify matches between two LineString FeatureCollections and measure the length of the match. A <strong>match</strong> is a correspondence between features of separate FeatureCollections (<span class="citation" data-cites="lei_lei_19">(<a href="#ref-lei_lei_19" role="doc-biblioref"><strong>lei_lei_19?</strong></a>)</span>).</p>
<p>The terminology to refer to the two FeatureCollections is inconsistent in the literature. For example, Zhang (<span class="citation" data-cites="zhang_2009">(<a href="#ref-zhang_2009" role="doc-biblioref"><strong>zhang_2009?</strong></a>)</span>) refers to the two FeatureCollections as the reference and target whereas the Java Conflation Suite (JCS) (<span class="citation" data-cites="jcs">(<a href="#ref-jcs" role="doc-biblioref"><strong>jcs?</strong></a>)</span>) refers to these as the reference and subject.</p>
<p>Instead, we use define the two FeatureCollections as the <strong>source</strong> and the <strong>target</strong> as utilized by Comber and Zeng’s work on areal interpolation (<span class="citation" data-cites="comber_zeng_2019">(<a href="#ref-comber_zeng_2019" role="doc-biblioref"><strong>comber_zeng_2019?</strong></a>)</span>). The source and target terminology is also much more commonly used in relational database management systems (RDBMS) and in the wider data science ecosystem. The use of these terms is an intentional recognition in the shift towards a more general field of spatial data science. The objective of the matching algorithm is to match features <em>from</em> the source <em>to</em> the target. Often the target is a more detailed and known collection of features.</p>
<p>In the process matching features, <strong>candidate</strong>s are found. A candidate is a source feature that <em>may</em> correspond to a target feature. If a candidate passes tests, it is then deemed a match. After matches have been found, attributes from the source feature are often transferred to the target feature. This process of attribute transfer is referred to as <strong>integration</strong> (FIXME CITE).</p>
</section>
<section id="existing-algorithms" class="level2">
<h2 class="anchored" data-anchor-id="existing-algorithms">Existing algorithms</h2>
<ul>
<li>there is a vast literature dedicated to matching linestring features between datasets. These can be thought of a category of binary classification algorithms that identify if a feature in the source FeatureCollection is a match to the target.</li>
<li>the classification is often based on geometric or semantic criteria, or both. The true challenge lies in the absence of semantic information. We therefore focus on matching strictly based on geometric criteria.</li>
<li>most commonly these criteria are location (proximity), orientation (angle), length, and shape similarity (often measured by some type of distance e.g.&nbsp;freshet, hausdorff or avg. euclidean from linestring vertices)</li>
</ul>
<p>Some choice algorithms. By far not exhaustive. Demonstrate some common unique strategies that are employed</p>
<p>Goodchild and Hunter 1997 introduce a buffer based algorithm which calculates the proportion of length covered by a target and source feature. They state that</p>
<blockquote class="blockquote">
<p>we suggest that a similar approach based on the percentage of the reference source length rather than the tested source might be more related to generalization…</p>
</blockquote>
<ul>
<li><p>Our algorithm, due to its reporting of shared overlap permits us to adapt the Goodchild algorithm and use % source length overlap as a cut off.</p>
<ul>
<li>The issue here is that there may be complete overlap from the source but the source may continue well past. we must address this. This is why we will lean on areal weighted interpolation</li>
</ul></li>
<li><p>Java Conflation Suite (JCS, 2003)</p></li>
<li><p>delimited strokes algorithm 2009 zhang</p></li>
<li><p>Kim et al., 2017 creates an algorithm to conflate historic road network with new ones</p>
<ul>
<li>uses a number of spatial similarity measures with c4.5 decision tree to classify</li>
<li>“linear directional mean” of each line segment in a LineString
<ul>
<li>challenging for longer linestrings with many segments</li>
</ul></li>
<li>shorter line median Hausdorff distance (SMHD)</li>
<li>absolute value of cosine similarity (aCS)
<ul>
<li>note we do something very similar</li>
</ul></li>
</ul></li>
<li><p>(Chehreghan &amp; Abbaspour, 2018) use a genetic algorithm. These are computational expensive and do not sacle well</p></li>
<li><p>Esri conflation toolset: buffer analysis and similarity</p></li>
<li><p>overline approach (morgan and lovelace)</p></li>
</ul>
<section id="spatial-criteria" class="level3">
<h3 class="anchored" data-anchor-id="spatial-criteria">Spatial Criteria</h3>
<p>our algorithm can be thought of as an extension of buffer and orientation analysis</p>
<ul>
<li><p>location / proximity measured as a distance buffer (of sorts)</p></li>
<li><p>orientation (angle)</p></li>
<li><p>where we differ is in the use of length</p></li>
<li><p>most existing algorithms perform matching between the source and target based on a measure of length of each LineString. Common are average euclidean distance, hausdorff, and frechet distance.</p></li>
<li><p>each of these evaluates the linestrings in their entirety</p></li>
<li><p>the algorithms then use the spatial criteria to perform a binary classification of either a match or not</p></li>
<li><p>we do</p></li>
</ul>
</section>
</section>
<section id="algorithm-overview" class="level2">
<h2 class="anchored" data-anchor-id="algorithm-overview">Algorithm overview</h2>
<ul>
<li><p>“a good matching algorithm should be able to create high quality results at a high speed.” (Zhang, 2009)</p></li>
<li><p>many algorithms are focused on 1:1 correspondence. ours supports <code>m:n</code> correspondence. Each feature in the target FeatureCollection can be matched as few as 0 times or to every feature in the source FeatureCollection.</p>
<ul>
<li>Our approach considers all relationships “including one-to-null, null-to-one, one-to-one, one-to-many, many-to-one, and many-to many.” (Chehreghan &amp; Abbaspour, 2017, 10.1080/15481603.2017.1338390)</li>
<li>^ related to above, we need to document the cardinality of our approach one-to-many there is no 1:1 matching of linestrings (Lei, Ting; Lei, Zhen (2019).)</li>
<li><blockquote class="blockquote">
<p>Beyond the one‐to‐one case, however, matching becomes more complicated and less well‐defined.</p>
</blockquote></li>
</ul></li>
<li><p>consider our algorithm as a way of identifying potential matches that can be pruned if desired</p>
<ul>
<li>we do not provide a binary classification but a way to identify correspondence between a target and source and measure the amount of correspondence.</li>
</ul></li>
</ul>
<p>The proposed algorithm aims to match elements of two sets of LineStrings that are topologically similar and estimate the amount of shared length between each pair of matched line strings.</p>
<p>Each LineString is composed of one or more Lines which is comprised of a single start or end point. The approximate network matching algorithm constructs two R* spatial indices over the component lines in <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. Intersection candidates between the two trees are used to limit the search space. For each candidate pair, the angle of the slopes are compared to determine if they are approximately parallel (parallelish). If the slopes are approximately parallel and the lines are within a minimum separable distance of each other, they are considered to match. The overlapping region between the matched lines is used to compute the shared length.</p>
<p>The result of the matching algorithm is a B-tree which can be used to generate a row-compressed sparse matrix.</p>
<section id="identify-match-candidates" class="level3">
<h3 class="anchored" data-anchor-id="identify-match-candidates">Identify match candidates</h3>
<p>To identify matches between <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> we do not look at the LineStrings in their totality, but rather, by their individual components. <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are comprised of one or more LineStrings index by <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> respectively. Each linestring is composed of one or more lines indexed as <span class="math inline">\(k\)</span>. Matches are found between elements of <span class="math inline">\(A_{ik}\)</span> and <span class="math inline">\(B_{jk}\)</span> using two R-trees.</p>
<p>We create an empty R-tree, <span class="math inline">\(Tree_A\)</span>. For each line <span class="math inline">\(A_{ik}\)</span> we compute the slope of the line and insert the geometry, slope, and index into the tree.</p>
<p>Next we create another empty R-tree, <span class="math inline">\(Tree_B\)</span>, in which we will store each line in <span class="math inline">\(B_{jk}\)</span>. However, instead of using the axis-aligned bounding box of <span class="math inline">\(B_{jk}\)</span>, we create a newer, larger one, based on a distance tolerance, <span class="math inline">\(DT\)</span>. The distance tolerance is used to expand the search for matches. We compute the AABB of <span class="math inline">\(B_{jk}\)</span>, then expand the AABB by <span class="math inline">\(DT\)</span> in both the x and y directions. After doing so, we insert the geometry, slope, and index into <span class="math inline">\(Tree_B\)</span></p>
<div>

</div>
<div class="cell quarto-layout-panel" data-layout-ncol="2">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="paper_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="672"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="paper_files/figure-html/unnamed-chunk-2-2.png" class="img-fluid" width="672"></p>
</div>
</div>
</div>
<p>If AABBs between <span class="math inline">\(Tree_A\)</span> and <span class="math inline">\(Tree_B\)</span> are intersecting, it means that that the lines <span class="math inline">\(A_{ik}\)</span> and <span class="math inline">\(B_{jk}\)</span> might be within <span class="math inline">\(DT\)</span> of each other and should be checked to see if they are considered matches.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="paper_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="matching-criteria" class="level3">
<h3 class="anchored" data-anchor-id="matching-criteria">Matching Criteria</h3>
<p>Candidate matches as determined by intersecting AABBs must then be further evaluated. Lines <span class="math inline">\(A_{ik}\)</span> and <span class="math inline">\(B_{jk}\)</span> must be approximately parallel (parallelish) to be considered a match. To this end, an angle tolerance <span class="math inline">\(AT\)</span> is defined. We take the inverse tangent of the slopes of lines <span class="math inline">\(A_{ik}\)</span> and <span class="math inline">\(B_{jk}\)</span> to find their angle. If the difference between these two angles are less than or equal to <span class="math inline">\(AT\)</span>, we deem them tolerant or, parallelish.</p>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="paper_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption>Matched lines with 15° angle tolerance and 2.5 meter distance tolerance.</figcaption>
</figure>
</div>
</div>
</div>
<p>Being confident that the <span class="math inline">\(A_{ik}\)</span> and <span class="math inline">\(B_{jk}\)</span> are parallelish, we next need to determine if they are within the distance tolerance determined by <span class="math inline">\(DT\)</span>. This is done by measuring the minimum separable distance between <span class="math inline">\(A_{ik}\)</span> and <span class="math inline">\(B_{jk}\)</span>. If both conditions are satisfied, then the lines are matched. Following, the shared segment length must be calculated.</p>
</section>
<section id="caclulating-segment-overlap" class="level3">
<h3 class="anchored" data-anchor-id="caclulating-segment-overlap">Caclulating segment overlap</h3>
<p>Once two lines <span class="math inline">\(A_{ik}\)</span> and <span class="math inline">\(B_{jk}\)</span> have been determined to be matches, we need to evaluate how much overlap exists between the two lines. This overlap is defined by the segment length of <span class="math inline">\(A_{ik}\)</span> contained in the overlap in the x or y dimension between <span class="math inline">\(A_{ik}\)</span> or <span class="math inline">\(B_{jk}\)</span>.</p>
<p>Based on the angle of the line <span class="math inline">\(A_{ik}\)</span>, <span class="math inline">\(\theta_{A_{ik}}\)</span>, we either calculate the overlap in the line segments in either the x or y dimension.</p>
<p><img src="assets/line-seg-overlap-top.png" class="img-fluid"></p>
<p>If <span class="math inline">\(\theta_{A_{ik}} \le 45^{\circ}\)</span>, we calculate the overlap between the range of x values of <span class="math inline">\(A_{ik}\)</span> and <span class="math inline">\(B_{jk}\)</span>, <span class="math inline">\((x_{min}, x_{max})\)</span>. Using the slope of <span class="math inline">\(A_{ik}\)</span>, solve for the values of y in the equation of the line. Using the calculated values of y, calculate the length of the line segment. If <span class="math inline">\(\theta_{A_{ik}} \gt 45^{\circ}\)</span>, we instead calculate the overlap in the range of y values and subsequently solve for x, then calculate the length of the line segment. Note that if there is no overlap in the x or y dimension and even if both matching criteria were met, there will be no shared length, and the resultant value with be 0.</p>
</section>
</section>
<section id="algorithm-implementation" class="level2">
<h2 class="anchored" data-anchor-id="algorithm-implementation">Algorithm Implementation</h2>
<div id="alg-approx-net-matching" class="pseudocode-container" data-line-number="true" data-line-number-punc=":" data-no-end="false" data-comment-delimiter="//" data-alg-title="Algorithm" data-pseudocode-index="1" data-indent-size="1.2em">
<div class="pseudocode">
\begin{algorithm} \caption{Approximate Network Matching} \begin{algorithmic} \State // Initialize R-trees for LineString components in sets A and B \Procedure{ApproxNetworkMatch}{$A, B, DT, AT$} \State $Tree_A \gets$ InitializeEmptyRTree() \For{each $A_{ik} \in A$} \State $slope_{A_{ik}} \gets$ ComputeSlope($A_{ik}$) \State InsertIntoRTree($Tree_A, i, A_{ik}, slope_{A_{ik}}$) \EndFor \State $Tree_B \gets$ InitializeEmptyRTree() \For{each $B_{jk} \in B$} \State $expandedAABB_{B_{jk}} \gets$ ExpandAABB($B_{jk}, DT$) \State InsertIntoRTree($Tree_B, j, B_{jk}, expandedAABB_{B_{jk}}$) \EndFor \State // Identify potential match candidates \For{each pair $(A_{ik}, B_{jk})$ with intersecting AABBs} \If{IsParallelish($slope_{A_{ik}}, slope_{B_{jk}}, AT$) and IsWithinDistance($A_{ik}, B_{jk}, DT$)} \State // Calculate shared segment length \State $overlapLength \gets$ CalculateOverlapLength($A_{ik}, B_{jk}$) \State // Store matched pair and overlap length \State StoreOrUpdateMatchedPair($A_{ik}, B_{jk}, overlapLength$) \EndIf \EndFor \State \Return MatchedPairs \EndProcedure \State // Helper functions \Function{IsParallelish}{$slope_{A}, slope_{B}, AT$} \State $angle_A \gets \arctan(slope_{A})$ \State $angle_B \gets \arctan(slope_{B})$ \State \Return $(|angle_A - angle_B| \le AT)$ \EndFunction \Function{IsWithinDistance}{$A_{ik}, B_{jk}, DT$} \State $minDistance \gets$ ComputeMinSeparableDistance($A_{ik}, B_{jk}$) \State \Return $(minDistance \le DT)$ \EndFunction \Function{CalculateOverlapLength}{$A_{ik}, B_{jk}$} \State $\theta_{A_{ik}} \gets$ ComputeAngle($A_{ik}$) \If{$\theta_{A_{ik}} \le 45^\circ$} \State $overlapLength \gets$ CalculateXOverlap($A_{ik}, B_{jk}$) \Else \State $overlapLength \gets$ CalculateYOverlap($A_{ik}, B_{jk}$) \EndIf \State \Return $overlapLength$ \EndFunction \end{algorithmic} \end{algorithm}
</div>
</div>
</section>
<section id="integration-of-numeric-attributes" class="level2">
<h2 class="anchored" data-anchor-id="integration-of-numeric-attributes">Integration of Numeric Attributes</h2>
<ul>
<li><p>we integrate principles from areal weighted interpolation and geometric conflation to provide an algorithm that matches geometries and performs attribute interpolation for complete and partial matches</p></li>
<li><p>by de-emphasizing the importance of exacty 1-1 matches and relying on principles of spatial interpolation we can integrate datasets that are not representational of identical phenomena but rather similar ones. We remove the emphasis on measures of fit essentially</p></li>
<li><p>in the cases where a complete match is identified this ammounts to a 1:1 attribute transfer</p></li>
<li><p>we rely on intensive and extensive attribute transfer.</p></li>
<li><p>TODO CITE r-spatial book and Tobler pysal library</p></li>
<li><p>the shared length between i and j may exceed the total length of i or j. This occurs when multiple matches are made between components most often in parallel ways</p></li>
</ul>
<section id="extensive-numeric-attribute-integration" class="level3">
<h3 class="anchored" data-anchor-id="extensive-numeric-attribute-integration">Extensive Numeric Attribute Integration</h3>
<p>sum of shared length / length of y *</p>
<p>let the shared length between target i and source j be the variable <span class="math inline">\(SL_{ij}\)</span></p>
<p><span class="math display">\[
\hat{Y}_i = \sum_{j} \frac{SL_{ij}}{length(j)} \times Y_j
\]</span></p>
</section>
<section id="intensive-numeric-attribute-integration" class="level3">
<h3 class="anchored" data-anchor-id="intensive-numeric-attribute-integration">Intensive Numeric Attribute Integration</h3>
<p><span class="math display">\[
\hat{Y}_i = \text{mean}\left(\frac{SL_{ij}}{length(i)} \times Y_j\right)
\]</span></p>
</section>
</section>
<section id="integration-of-categorical-attributes" class="level2">
<h2 class="anchored" data-anchor-id="integration-of-categorical-attributes">Integration of Categorical Attributes</h2>
<p>Similar to the the approach taken for numeric attributes, we can also apply these to categorical variables. Say we have a categorical variable <span class="math inline">\(Y\)</span> with <span class="math inline">\(k\)</span> unique values. For each <span class="math inline">\(j\)</span> we calculate a frequency table for each <span class="math inline">\(Y_{jk}\)</span>. We create new variable for each unique <span class="math inline">\(Y_k\)</span>. <span class="math inline">\(Y_{ik}\)</span> becomes a numeric variable of the frequency. <span class="math inline">\(Y_{jk}\)</span> is a dummy variable. We now apply the same approach for extensive and intensive attribute integration for each new dummy variable.</p>
<section id="extensive-categorical-attribute-integration" class="level3">
<h3 class="anchored" data-anchor-id="extensive-categorical-attribute-integration">Extensive Categorical Attribute Integration</h3>
<p><span class="math inline">\(\hat{Y_{ik}}\)</span> is equal to the shared length divided by the length of j times <span class="math inline">\(Y_{jk}\)</span> summed for all <span class="math inline">\(ij\)</span> pairs. Note that <span class="math inline">\(Y_{jk}\)</span> can take on only the values of 1 or 0.</p>
<p><span class="math display">\[
\hat{Y_{ik}} = \sum_{j}{\frac{SL_{ij}}{length(j)}} \times Y_{jk}
\]</span></p>
</section>
<section id="intensive-categorical-attribute-integration" class="level3">
<h3 class="anchored" data-anchor-id="intensive-categorical-attribute-integration">Intensive Categorical Attribute Integration</h3>
<p><span class="math display">\[
\hat{Y_{ik}} = \text{mean}\left(\frac{SL_{ij}}{length(i)} \times Y_{jk}\right)
\]</span></p>
</section>
</section>
<section id="adaptability-of-approximate-network-matching" class="level2">
<h2 class="anchored" data-anchor-id="adaptability-of-approximate-network-matching">Adaptability of Approximate Network Matching</h2>
<ul>
<li>our algorithm is incredible flexible
<ul>
<li>for example, you can match features that have no overlap if they are within distance tolerance and match the orientation critera to find abutting neighbors</li>
<li>use results to efficiently narrow down matching candidates for manual verification</li>
</ul></li>
<li>can be used as a way to very quickly narrow down matches. Shared overlap can be used to provide a binary classification</li>
</ul>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<ul>
<li><p>This algorithm is limited in that it is designed in <span class="math inline">\(\Bbb{R}^2\)</span> space. As such, there is no support for 3-dimensional or spherical coordinates. It is, however, conceivable to apply the same principles to these scenarios. The challenge, then, is to determine overlap regions, lengths, and lines-segments.</p></li>
<li><p>3D could be important though not many network datasets keep track of the height of points. Otherwise, measuring distance in 3 dimension for candidates could be useful.</p></li>
<li><p>limited in that the geometries must be in the same coordinate system and must be proximal to eachother. Does not work for arbitrarily scaled geometries</p></li>
<li><p>does not handle geometry shift (Lei, Ting; Lei, Zhen (2019))</p>
<ul>
<li>we make no affine transformations to handle shifts in geometries</li>
</ul></li>
</ul>
<hr>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references">References</h3>
<p><span class="citation" data-cites="morgan_travel_2021">(<a href="#ref-morgan_travel_2021" role="doc-biblioref">Morgan and Lovelace 2021</a>)</span> <span class="citation" data-cites="rawlingson_overlaying_2015">(<a href="#ref-rawlingson_overlaying_2015" role="doc-biblioref">Rawlingson 2015</a>)</span> <span class="citation" data-cites="chehreghan_new_2017">(<a href="#ref-chehreghan_new_2017" role="doc-biblioref">Chehreghan and Abbaspour 2017</a>)</span> <span class="citation" data-cites="goodchild_simple_1997">(<a href="#ref-goodchild_simple_1997" role="doc-biblioref">Goodchild and Hunter 1997</a>)</span> <span class="citation" data-cites="zhang_methods_nodate">(<a href="#ref-zhang_methods_nodate" role="doc-biblioref">Zhang, n.d.</a>)</span> <span class="citation" data-cites="lei_optimal_2019">(<a href="#ref-lei_optimal_2019" role="doc-biblioref">Lei and Lei 2019</a>)</span></p>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-chehreghan_new_2017" class="csl-entry" role="listitem">
Chehreghan, A., and R. Ali Abbaspour. 2017. <span>“A New Descriptor for Improving Geometric-Based Matching of Linear Objects on Multi-Scale Datasets.”</span> <em>GIScience &amp; Remote Sensing</em> 54: 836–61. <a href="https://doi.org/10.1080/15481603.2017.1338390">https://doi.org/10.1080/15481603.2017.1338390</a>.
</div>
<div id="ref-goodchild_simple_1997" class="csl-entry" role="listitem">
Goodchild, Michael F., and Gary J. Hunter. 1997. <span>“A Simple Positional Accuracy Measure for Linear Features.”</span> <em>International Journal of Geographical Information Science</em> 11 (3): 299–306. <a href="https://doi.org/10.1080/136588197242419">https://doi.org/10.1080/136588197242419</a>.
</div>
<div id="ref-lei_optimal_2019" class="csl-entry" role="listitem">
Lei, Ting, and Zhen Lei. 2019. <span>“Optimal Spatial Data Matching for Conflation: <span>A</span> Network Flow‐based Approach.”</span> <em>Transactions in GIS</em> 23 (5): 1152–76. <a href="https://doi.org/10.1111/tgis.12561">https://doi.org/10.1111/tgis.12561</a>.
</div>
<div id="ref-morgan_travel_2021" class="csl-entry" role="listitem">
Morgan, Malcolm, and Robin Lovelace. 2021. <span>“Travel Flow Aggregation: <span>Nationally</span> Scalable Methods for Interactive and Online Visualisation of Transport Behaviour at the Road Network Level.”</span> <em>Environment and Planning B: Urban Analytics and City Science</em> 48 (6): 1684–96. <a href="https://doi.org/10.1177/2399808320942779">https://doi.org/10.1177/2399808320942779</a>.
</div>
<div id="ref-rawlingson_overlaying_2015" class="csl-entry" role="listitem">
Rawlingson, Barry. 2015. <span>“Overlaying Lines and Aggregating Their Values for Overlapping Segments Using <span>R</span>?”</span> <a href="https://gis.stackexchange.com/questions/139681/overlaying-lines-and-aggregating-their-values-for-overlapping-segments-using-r">https://gis.stackexchange.com/questions/139681/overlaying-lines-and-aggregating-their-values-for-overlapping-segments-using-r</a>.
</div>
<div id="ref-zhang_methods_nodate" class="csl-entry" role="listitem">
Zhang, Meng. n.d. <span>“Methods and <span>Implementations</span> of <span>Road</span>-<span>Network</span> <span>Matching</span>.”</span>
</div>
</div>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    const typesetMath = (el) => {
      if (window.MathJax) {
        // MathJax Typeset
        window.MathJax.typeset([el]);
      } else if (window.katex) {
        // KaTeX Render
        var mathElements = el.getElementsByClassName("math");
        var macros = [];
        for (var i = 0; i < mathElements.length; i++) {
          var texText = mathElements[i].firstChild;
          if (mathElements[i].tagName == "SPAN") {
            window.katex.render(texText.data, mathElements[i], {
              displayMode: mathElements[i].classList.contains('display'),
              throwOnError: false,
              macros: macros,
              fleqn: false
            });
          }
        }
      }
    }
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        for (let i = 0; i < 2; i++) {
          container.appendChild(note.children[i].cloneNode(true));
        }
        typesetMath(container);
        return container.innerHTML
      } else {
        typesetMath(note);
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      typesetMath(note);
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js" type="text/javascript"></script>
<script type="text/javascript">
(function(d) {
  d.querySelectorAll(".pseudocode-container").forEach(function(el) {
    let pseudocodeOptions = {
      indentSize: el.dataset.indentSize || "1.2em",
      commentDelimiter: el.dataset.commentDelimiter || "//",
      lineNumber: el.dataset.lineNumber === "true" ? true : false,
      lineNumberPunc: el.dataset.lineNumberPunc || ":",
      noEnd: el.dataset.noEnd === "true" ? true : false,
      titlePrefix: el.dataset.algTitle || "Algorithm"
    };
    pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
  });
})(document);
(function(d) {
  d.querySelectorAll(".pseudocode-container").forEach(function(el) {
    titleSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
    titlePrefix = el.dataset.algTitle;
    titleIndex = el.dataset.chapterLevel ? el.dataset.chapterLevel + "." + el.dataset.pseudocodeIndex : el.dataset.pseudocodeIndex;
    titleSpan.innerHTML = titlePrefix + " " + titleIndex + " ";
  });
})(document);
</script>




</body></html>