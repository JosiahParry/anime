---
title: "ANIME: Approximate Network Integration, Matching and Enrichment"

bibliography: refs.bib

author: 
  - name: Josiah Parry
    affiliation: Environmental Systems Research Institute, Redlands, CA, USA 
    orcid: 0000-0001-9910-865X
  - name: Zhao Wang
    affiliation: Leeds Institute for Transport Studies, University of Leeds, UK
    orcid: 0000-0002-4054-0533
  - name: Robin Lovelace
    affiliation: Leeds Institute for Transport Studies, University of Leeds, UK
    orcid: 0000-0001-5679-6536

format:
  pdf:
    include-in-header:
      text: |
        \usepackage{lineno}
        \linenumbers
        \usepackage{amsmath}
        \usepackage{algorithm}
        \usepackage{algpseudocode}
        \usepackage{float}
filters:
  - pseudocode
  
engine: knitr
number-sections: true
execute: 
  echo: false
  message: false
  warning: false
editor: 
  markdown: 
    wrap: sentence
---


```{r}
#| eval: false
if (!"quarto" %in% rownames(installed.packages())) {
  install.packages("quarto")
}
quarto::quarto_render("paper/README.qmd")
```


# Abstract {.unnumbered}

Reconciling topologically different linestrings is a fundamental challenge in spatial data science, particularly when integrating network datasets from disparate sources.
Existing methods can be limiting due to absence of join keys and the requirement of direct transfer of attributes.
This paper presents ANIME (Approximate Network Integration, Matching and Enrichment), a novel segment-level geometric matching algorithm implemented in a high-performance, open-source Rust library with bindings to R and Python.
ANIME quantifies the degree of correspondence between line geometries through shared length calculations, enabling robust handling of m:n relationships and complex topological dissimilarities.
The algorithm leverages R*-tree spatial indexing with angle and distance-based matching criteria, combined with overlap computation methods that adapt to line segment orientation.
The algorithm computes shared length ($SL_{ij}$) between corresponding features, providing the foundation for extensive and intensive attribute interpolation methods that enable statistically sound attribute transfer.
Experimental validation demonstrates fast and memory efficient performance handling generalized-to-detailed geometry matching, one-to-many correspondences, and attribute integration.
Applications span transport planning, hydrographic conflation, ecological modeling, and infrastructure management, offering a robust foundation for complex geospatial integration tasks requiring weighted aggregations and feature subset identification based on shared geometric characteristics.

# Keywords {.unnumbered}

Network Conflation, Spatial Data Integration, Geometric Matching, Attribute Transfer, Spatial Interpolation, R-tree Indexing, Linestring Matching

{{< pagebreak >}}

# Highlights {.unnumbered}

- A novel segment-level algorithm for matching topologically dissimilar linear network datasets with mathematical rigor.
- High-performance implementation in Rust with comprehensive R and Python bindings for broad accessibility.
- Quantitative correspondence measurement using shared length calculations, supporting m:n relationships instead of 1:1 or 1:m relationships.
- Mathematically grounded extensive and intensive attribute interpolation methods for both numeric and categorical data.

{{< pagebreak >}}

# Introduction

A long-standing challenge in spatial data science is the reconciliation of vector linestring datasets.
Such datasets are used in many fields, including transport planning, which increasingly requires the integration of multiple representations of linear transport networks such as those from different government agencies or commercial providers.
These datasets often represent the same real-world phenomena but are topologically different.
Join keys are typically absent, making it unclear which features should be matched between datasets.
Even when features can be identified for joining, direct attribute transfer is often inappropriate because attributes (e.g., speed limits, traffic volumes) are intended to be associated with specific geometries and may not have direct counterparts in the other dataset.
Consequently, a weighted approach is necessary to accurately associate attributes during integration.
As noted by @lei_optimal_2019, "Due to the complexity and limitations of existing methods, planners and analysts often have to employ a heavily manual conflation^[Conflation is a two-step process that first identifies corresponding geometries between datasets and then transfers attributes between matched features.] process, which is time‐consuming and often prohibitively expensive."

The need for robust automated integration methods is growing as vast quantities of geospatial data are derived from remotely sensed imagery [@samal_review_2004] and large-scale feature extraction projects.
Features from these sources may not be complete or entirely accurate but they may be used to supplement missing data or reflect recent changes in a primary dataset.
Several persistent challenges complicate the matching process: 

- matching generalized geometry to more detailed representations [@kim_conflation_2017; @mustiere_matching_2008]
- different representations of the same feature (e.g., a multi-lane highway as a single line in one dataset and multiple parallel lines in another [@zhang_methods_nodate])
-  addressing one-to-many or many-to-many correspondence scenarios
In the absence of reliable semantic information or join keys, a purely geometric approach becomes essential [@samal_review_2004].

## Existing approaches and limitations

The extensive literature on network conflation predominantly frames the problem as binary feature classification, determining whether a source feature matches a target feature based on geometric similarity measures including proximity, orientation (angular similarity), length ratios, and shape similarity metrics such as Fréchet distance, Hausdorff distance, or vertex-based Euclidean measures [@samal_review_2004].

Notable contributions to the field encompass diverse methodological frameworks:
Buffer-based methods, exemplified by @goodchild_simple_1997, calculate proportional coverage between geometries but lack robust handling of complex topological relationships.
The Java Conflation Suite [@davis_java_2003] provides a comprehensive toolkit but remains limited to binary matching decisions.
Advanced algorithmic approaches include the delimited strokes algorithm [@zhang_methods_nodate], the overline method [@morgan_travel_2021], and commercial solutions like Esri's conflation toolset [@esri_conflation_2023], which combines buffer analysis with multivariate similarity metrics.
Machine learning approaches, such as @kim_conflation_2017's C4.5 decision tree using spatial similarity measures (linear directional mean, shorter line median Hausdorff distance, absolute cosine similarity), attempt to automate classification decisions but remain constrained by binary output frameworks.

A fundamental limitation shared across existing methods is their reliance on binary matching frameworks that inadequately represent the **partial correspondences** characteristic of real-world network data.
These approaches fail to quantify the degree of overlap between features, limiting their applicability for weighted attribute transfer and preventing accurate representation of complex geometric relationships.

## ANIME: A novel approach and research objectives

This paper presents ANIME (Approximate Network Integration, Matching and Enrichment), a fundamentally different approach to network conflation that abandons binary matching decisions in favor of **quantitative correspondence measurement**.
ANIME employs segment-level geometric analysis to quantify partial overlaps with mathematical rigor, enabling robust handling of complex topological relationships and providing a statistically sound foundation for weighted attribute transfer.

This work aims to address the limitations of existing methods through four primary research objectives:

1.  **Develop a quantitative correspondence framework** that measures degrees of geometric overlap rather than binary matching decisions, enabling precise representation of partial correspondences between network features.

2.  **Establish mathematical foundations** for weighted attribute transfer through rigorous geometric analysis and spatial interpolation theory.

3.  **Design and implement** a high-performance algorithmic solution that scales efficiently for large network datasets while maintaining broad accessibility across programming environments.

4.  **Validate the approach** through comprehensive testing on real-world transportation networks to demonstrate practical applicability and effectiveness.

The remainder of this paper is organized as follows.
Section 2 details the mathematical foundation and algorithmic methodology.
Section 3 presents the core implementation architecture and performance considerations.
Section 4 provides a comprehensive case study applying ANIME to real-world road network data.
Section 5 discusses results, limitations, and applications.
Finally, Section 6 provides concluding remarks and suggests directions for future research.

# Mathematical Foundation and Methodology

This section establishes the mathematical foundation of ANIME, which consists of two main components: (1) a core geometric matching algorithm that computes shared lengths between features, and (2) attribute interpolation methods that utilize these matching results for statistically sound attribute transfer.

## Mathematical framework

### Algorithm parameters

The ANIME matching algorithm operates on two sets of linestring features with algorithm parameters summarized in @tbl-variables-parameters.

| Variable/Parameter           | Symbol    | Description                                                                    |
| ---------------------------- | --------- | ------------------------------------------------------------------------------ |
| Source features              | $A$       | The input `FeatureCollection` from which attributes are transferred           |
| Target features              | $B$       | The input `FeatureCollection` to which features are being matched             |
| Distance Tolerance           | $DT$      | The maximum Euclidean distance for segment matching (in map units)            |
| Angle Tolerance              | $AT$      | The maximum angle difference (degrees) for parallel segment consideration     |

: Algorithm parameters for the ANIME matching procedure {#tbl-variables-parameters}


Each LineString in datasets $A$ and $B$ is formally decomposed into its component line segments:

- $A_{ik}$: The $k$-th line segment of the $i$-th LineString in source dataset $A$
- $B_{jk}$: The $k$-th line segment of the $j$-th LineString in target dataset $B$

The matching process is performed at the segment level to provide a granular assessment of correspondence.
This process involves five main steps:

1. **Linestring decomposition**: Breaking down each LineString into constituent line segments
2. **AABB calculation and spatial indexing**: Computing bounding boxes and constructing R-trees for efficient spatial queries  
3. **Candidate identification**: Using spatial indexing to find potentially matching segment pairs
4. **Match selection**: Filtering candidates based on geometric constraints (parallel-ish orientation and distance thresholds)
5. **Overlap calculation**: Computing shared length between confirmed matches

### Algorithm output structure

The ANIME matching algorithm produces a match matrix containing:
- Source feature lengths
- Target feature lengths  
- Match records with source indices, target indices, and shared lengths ($SL_{ij}$)

From this output structure, weighted proportions can be calculated on-demand:
- Source-weighted proportion: $sw_{ij} = SL_{ij} / \text{length}(i)$
- Target-weighted proportion: $tw_{ij} = SL_{ij} / \text{length}(j)$

This design separates the core geometric matching from subsequent attribute interpolation applications.

### Linestring decomposition

Linestring decomposition forms the foundational step that distinguishes ANIME from feature-level matching approaches. Each LineString geometry is systematically decomposed into its constituent line segments, enabling granular geometric analysis that is essential for handling complex topological relationships.

**Mathematical Definition**: For a LineString $L_i$ defined by an ordered sequence of vertices $\{v_1, v_2, \ldots, v_n\}$ where $v_k = (x_k, y_k)$, the decomposition yields $(n-1)$ line segments:

$$L_{i,k} = \overline{v_k v_{k+1}} \text{ for } k = 1, 2, \ldots, n-1 \tag{1}$$ {#eq-decomposition}

Each line segment $L_{i,k}$ is formally defined as the straight line connecting consecutive vertices $v_k$ and $v_{k+1}$, with geometric properties:

- **Length**: $|L_{i,k}| = \sqrt{(x_{k+1} - x_k)^2 + (y_{k+1} - y_k)^2}$
- **Slope**: $m_{i,k} = \frac{y_{k+1} - y_k}{x_{k+1} - x_k}$ (undefined for vertical segments)
- **Angle**: $\theta_{i,k} = \arctan(m_{i,k})$
- **Bounding Box**: $\text{AABB}_{i,k} = [\min(x_k, x_{k+1}), \max(x_k, x_{k+1})] \times [\min(y_k, y_{k+1}), \max(y_k, y_{k+1})]$

This segment-level decomposition provides several critical advantages over traditional feature-level matching:

1. **Topological Resilience**: Complex LineString features with different vertex densities or slight geometric variations can still be matched at the segment level, even when their overall shapes differ significantly.

2. **M:N Relationship Handling**: A single segment from one network can match multiple segments from another network, and vice versa, naturally accommodating the complex correspondence patterns common in real-world network data.

3. **Partial Overlap Quantification**: Rather than binary matching decisions (match/no-match), the algorithm can quantify the precise degree of correspondence between network features through segment-level shared length calculations.

4. **Computational Efficiency**: Segment-level processing enables efficient spatial indexing and reduces the complexity of geometric computations compared to complex multi-vertex LineString comparisons.

The decomposition process preserves the relationship between segments and their parent LineString features through indexing schemes $A_{ik}$ and $B_{jk}$, where $i$ and $j$ represent LineString indices and $k$ represents segment indices within each LineString. This indexing structure is essential for subsequent attribute aggregation and ensures that the segment-level matching results can be properly aggregated back to the feature level.

The decomposed segments serve as the fundamental units for all subsequent processing steps: spatial indexing, candidate identification, geometric validation, and overlap calculation. This granular approach enables ANIME to handle the complex geometric relationships that characterize real-world network conflation scenarios.

### Spatial indexing and candidate identification

Matches between $A$ and $B$ are not identified by considering the LineStrings in their totality, but rather by their individual components.
$A$ and $B$ are comprised of one or more LineStrings, indexed by $i$ and $j$ respectively.
Each linestring is composed of one or more line segments, indexed by $k$.
Matches are found between line segments $A_{ik}$ and $B_{jk}$ using two R-trees.

An empty R-tree, $Tree_A$, is created.
For each line segment $A_{ik}$, its slope is computed, and the geometry, slope, and index are inserted into the tree.
Next, another empty R-tree, $Tree_B$, is created to store each line segment in $B_{jk}$.
Instead of using the axis-aligned bounding box (AABB) of $B_{jk}$, a larger one is created based on the distance tolerance, $DT$, which expands the search radius for matches.
The AABB of $B_{jk}$ is computed and then expanded by $DT$ in both the x and y directions, such that the expanded AABB is defined as $[x_{\min} - DT, x_{\max} + DT] \times [y_{\min} - DT, y_{\max} + DT]$.
After doing so, the geometry, slope, and index are inserted into $Tree_B$.

```{r message = FALSE, echo = FALSE}
#| label: fig-aabb-construction
#| fig-cap: "Spatial indexing construction for ANIME's R*-tree implementation. Left: Standard axis-aligned bounding boxes (AABBs) for source network A segments (blue boxes). Right: Distance-buffered AABBs for target network B segments (orange boxes) expanded by 2.5-meter tolerance to accommodate geometric search radius. "
suppressMessages(library(sf))
library(rsgeo)
library(ggplot2)
library(patchwork)
conflicted::conflict_prefer("ggplot2", "rsgeo")

# box to crop geometry to
crop_box <- st_bbox(c("xmin" = 427200, xmax = 427500, ymin = 433550, ymax = 433700))

rnet_x <- "https://raw.githubusercontent.com/nptscot/networkmerge/main/data/rnet_armley.geojson" |>
  read_sf() |>
  st_geometry() |>
  st_transform(27700) |>
  st_crop(crop_box)

rnet_y <- "https://raw.githubusercontent.com/nptscot/networkmerge/main/data/rnet_armley_line.geojson" |>
  read_sf() |>
  st_crop(crop_box)



x <- as_rsgeo(sf::st_transform(rnet_x, 27700))
y <- as_rsgeo(st_transform(rnet_y, 27700))

# axis-aligned-bounding-box for x
xbb <- bounding_rect(explode_lines(x))

# creating bounding rects for y
# need to expand them
ybb <- bounding_rect(explode_lines(y))

# define function to expand the AABB
expand_aabb <- function(x, DT) {
  crds <- coords(x)
  # xmin, max, max, min, min
  # ymin min max max min
  crds[, 1] <- crds[, 1] + (c(-1, 1, 1, -1, -1) * DT)
  crds[, 2] <- crds[, 2] + (c(-1, -1, 1, 1, -1) * DT)
  rsgeo::geom_polygon(crds$x, crds$y, crds$polygon_id)
}

DT <- 2.5
xbb_sf <- st_as_sfc(xbb) |> st_set_crs(27700)
ybb_sf <- st_as_sfc(expand_aabb(ybb, DT)) |> st_set_crs(27700)

p1_left <- ggplot() +
  geom_sf(
    data = xbb_sf,
    fill = "#76b5c5", alpha = 0.25, lwd = 0.1
  ) +
  geom_sf(data = rnet_x, lwd = 0.2) +
  labs(subtitle = "Source Network AABBs") +
  theme_void()

p1_right <- ggplot() +
  geom_sf(
    data = ybb_sf,
    fill = "#e28743", alpha = 0.25, lwd = 0.1
  ) +
  geom_sf(data = rnet_y, alpha = 0.5) +
  labs(subtitle = "Target Network Distance-Buffered AABBs") +
  theme_void()

p3 <- ggplot() +
  geom_sf(
    data = xbb_sf,
    fill = "#76b5c5", alpha = 0.25, lwd = 0.1
  ) +
  geom_sf(
    data = ybb_sf,
    fill = "#e28743", alpha = 0.25, lwd = 0.1
  ) +
  geom_sf(data = rnet_x, alpha = 0.5, lwd = 0.15) +
  geom_sf(data = rnet_y, alpha = 0.5) +
  theme_void()

# Display the two-panel figure as referenced in caption
p1_left + p1_right 
```

The spatial indexing construction is illustrated in @fig-aabb-construction.
@fig-aabb-construction (left) shows how axis-aligned bounding boxes (AABBs) are created for the source network, while @fig-aabb-construction (right)  shows that the target network features distance-buffered envelopes.
If the AABBs of segments from $Tree_A$ and $Tree_B$ intersect, it indicates that the line segments $A_{ik}$ and $B_{jk}$ may be within the distance tolerance $DT$ of each other and are thus candidates for matching.

The network overlay shown in @fig-network-overlay provides the spatial context for understanding potential match candidates, where intersecting bounding boxes indicate segment pairs that require geometric validation.


```{r}
#| label: fig-network-overlay
#| fig-cap: "Overlay of source network A (blue with bounding boxes) and target network B (red with distance-buffered bounding boxes), showing potential match candidates where bounding boxes intersect."
p3
```

### Geometric validation (angle and distance tolerances)
Candidate matches identified through spatial indexing are further validated based on two geometric criteria: orientation and proximity.
A candidate pair of segments, $A_{ik}$ and $B_{jk}$, is considered a match only if they are approximately parallel and within the specified distance tolerance.
Parallelism is determined by comparing the absolute difference between the segments' angles against an angle tolerance, $AT$.
The angle $\theta$ for a segment is calculated from its slope $m$ as $\theta = \arctan(m)$.
Two segments are considered parallel if $|\theta_{A_{ik}} - \theta_{B_{jk}}| \le AT$.
Proximity is confirmed by measuring the minimum separable distance between the segments and ensuring it is less than or equal to the distance tolerance, $DT$. 

Once it is determined that $A_{ik}$ and $B_{jk}$ are approximately parallel (within the threshold set by the `angle_tolerance` argument), the next step is to verify that they are within the distance tolerance $DT$.
This check is performed by measuring the minimum separable distance between $A_{ik}$ and $B_{jk}$.
If both conditions are satisfied, the segments are considered a match.@fig-geometric-validation demonstrates a geometric validation example by showing how source line segments (solid lines) are matched to target segments (dashed lines) within a 15° angular and 2.5-meter distance tolerance.

```{r}
#| label: fig-geometric-validation
#| fig-cap: "Geometric validation example."
mtx <- anime::anime(
  rnet_y,
  rnet_x,
  2.5,
  15
)
mtx_df <- as.data.frame(mtx)
i <- 4
ydx <- which(mtx_df$target_id == i)
xx <- rnet_x[i]
yy <- rnet_y$geometry[mtx_df$source_id[ydx]]

# plot the lines that we will measure
ggplot() +
  geom_sf(data = yy) +
  geom_sf(data = xx, linetype = "dashed") +
  # labs(title = "Geometric Validation Example") +
  theme_void()
```


### Overlap calculation and shared length quantification

Once two line segments $A_{ik}$ and $B_{jk}$ are identified as a match, the extent of their overlap is calculated.
This overlap is defined as the length of the portion of segment $A_{ik}$ that is projected onto the overlapping range of either the x- or y-dimensions of the two segments.

The calculation of the overlap is performed in either the x or y dimension, depending on the angle of the line segment $A_{ik}$, $\theta_{A_{ik}}$. The shared segment length is calculated using the approach illustrated in @fig-segment-overlap.

![Schematic illustration of segment overlap calculation. The overlap length is determined by projecting line segments onto either the x-axis (for slopes ≤45°) or y-axis (for slopes >45°) and calculating the intersection of projected ranges.](assets/line-seg-overlap-top.png){#fig-segment-overlap}

## Attribute integration methods

While the core ANIME algorithm focuses solely on geometric matching and shared length computation, the resulting match matrix enables robust attribute transfer applications. The following methods utilize the computed shared lengths ($SL_{ij}$) for transferring attributes between matched features, supporting both numeric and categorical data types using principles from areal weighted interpolation.
Areal weighted interpolation is commonly used for extensive variables, where the value is dependent on the size of the area, like population counts [@comber_spatial_2019].
Intensive variables, which are independent of the area's size, such as population density or percentages, require a different approach.

**Numeric Attribute Integration**

For extensive variables (e.g., counts), the value for a target feature $j$, $\hat{Y}_j$, is estimated by summing the weighted values from all matching source features $i$.
The value of each source feature, $Y_i$, is weighted by the proportion of its length that is matched to target feature $j$.

$$
\hat{Y}_j = \sum_{i} \frac{SL_{ij}}{\text{length}(i)} \times Y_i \tag{2}
$$ {#eq-extensive}
 
For intensive variables (e.g., averages, rates), the value for a target feature $j$, $\hat{Y}_j$, is estimated as the weighted average of the values from all matching source features.
The value of each source feature $Y_i$ is weighted by the shared length of the match, $SL_{ij}$.

$$
\hat{Y}_j = \frac{\sum_{i} (SL_{ij} \times Y_i)}{\sum_{i} SL_{ij}} \tag{3}
$$ {#eq-intensive}

**Categorical Attribute Integration**

While the core ANIME algorithm does not directly handle categorical variables, client-side implementations can integrate them by first transforming them into numeric representations. A common approach is to convert a categorical variable into a set of binary dummy variables, one for each category. For a category $k$, the dummy variable $Y_{ik}$ is 1 if source feature $i$ has category $k$, and 0 otherwise.

@eq-extensive and @eq-intensive can then be used to integrate these dummy variables. Applying the extensive integration method (@eq-extensive) to $Y_{ik}$ yields the total length-weighted count of category $k$ transferred to the target feature. Applying the intensive integration method (@eq-intensive) yields the proportion of the matched length of the target feature that corresponds to category $k$. This approach is demonstrated in the R implementation.

# Core Implementation Architecture

This section details the high-performance implementation of ANIME, which is written in Rust to ensure performance and portability, with bindings for R and Python for broad accessibility. The core algorithm leverages the `rstar` crate for R*-tree spatial indexing and is outlined in the pseudocode below. The following subsections describe its architectural design, data structures, and optimization strategies.

```pseudocode
#| label: alg-approx-net-matching
#| html-indent-size: "1.2em"
#| html-comment-delimiter: "//"
#| html-line-number: true
#| html-line-number-punc: ":"
#| html-no-end: false
#| pdf-placement: "H"
#| pdf-line-number: true

\begin{algorithm}
\caption{Approximate Network Matching}
\begin{algorithmic}
\State // Initialize R-trees for LineString components in sets A and B
\Procedure{ApproxNetworkMatch}{$A, B, DT, AT$}
  \State $Tree_A \gets$ InitializeEmptyRTree()
  \For{each $A_{ik} \in A$}
    \State $slope_{A_{ik}} \gets$ ComputeSlope($A_{ik}$)
    \State InsertIntoRTree($Tree_A, i, A_{ik}, slope_{A_{ik}}$)
  \EndFor
  
  \State $Tree_B \gets$ InitializeEmptyRTree()
  \For{each $B_{jk} \in B$}
    \State $expandedAABB_{B_{jk}} \gets$ ExpandAABB($B_{jk}, DT$)
    \State InsertIntoRTree($Tree_B, j, B_{jk}, expandedAABB_{B_{jk}}$)
  \EndFor
  
  \State // Identify potential match candidates from intersecting AABBs
  \State $Candidates \gets$ FindIntersectingPairs($Tree_A, Tree_B$)
  
  \For{each candidate pair $(A_{ik}, B_{jk}) \in Candidates$}
    \If{IsParallelish($slope_{A_{ik}}, slope_{B_{jk}}, AT$) and IsWithinDistance($A_{ik}, B_{jk}, DT$)}
      \State // Calculate shared segment length
      \State $overlapLength \gets$ CalculateOverlapLength($A_{ik}, B_{jk}$)
      \State // Store matched pair and overlap length
      \State StoreOrUpdateMatch($i, j, overlapLength$)
    \EndIf
  \EndFor
  
  \State \Return MatchedPairs
\EndProcedure

\State // Helper functions
\Function{IsParallelish}{$slope_{A}, slope_{B}, AT$}
  \State $angle_A \gets \arctan(slope_{A})$
  \State $angle_B \gets \arctan(slope_{B})$
  \State \Return $(|angle_A - angle_B| \le AT)$
\EndFunction

\Function{IsWithinDistance}{$A_{ik}, B_{jk}, DT$}
  \State $minDistance \gets$ ComputeMinSeparableDistance($A_{ik}, B_{jk}$)
  \State \Return $(minDistance \le DT)$
\EndFunction

\Function{CalculateOverlapLength}{$A_{ik}, B_{jk}$}
  \State $\theta_{A_{ik}} \gets$ ComputeAngle($A_{ik}$)
  \If{$\theta_{A_{ik}} \le 45^\circ$}
    \State $overlapLength \gets$ CalculateXOverlap($A_{ik}, B_{jk}$)
  \Else
    \State $overlapLength \gets$ CalculateYOverlap($A_{ik}, B_{jk}$)
  \EndIf
  \State \Return $overlapLength$
\EndFunction
\end{algorithmic}
\end{algorithm}
```

## System architecture

ANIME follows a multi-layered architecture with a high-performance Rust core focused on geometric matching, complemented by language-specific bindings that provide attribute interpolation utilities for broad accessibility across the geospatial community.

### Core components

**Rust Core Algorithm**: The high-performance engine is implemented in Rust and leverages R*-tree spatial indexing. Key components include:

- **Spatial Indexing Engine**: An R*-tree implementation for efficient geometric queries.
- **Geometric Processing**: Algorithms for linestring decomposition, slope calculation, and shared length computation.

### Data structures

ANIME's implementation is built around several key data structures that enable efficient spatial matching and interpolation.

**Core Anime Struct**

The `Anime` struct serves as the central coordinator for the entire matching and interpolation process, maintaining spatial indices, tolerance parameters, and computed matches:

$$\text{Anime} = \{Tree_A, Tree_B, DT, AT, \text{matches}\} \tag{4}$$

where $Tree_A$ and $Tree_B$ are the source and target R*-trees, $DT$ is the distance tolerance, $AT$ is the angle tolerance, and $\text{matches}$ stores the computed correspondences.

**Target Line Structure**

The target line structure represents LineString components with automatic distance buffering, mathematically defined as:

$$\text{TarLine} = (L_{segment}, DT) \tag{5}$$

where $L_{segment}$ is the geometric line segment and $DT$ is the distance tolerance for spatial buffering.

**Match Candidate Structure**

Each potential match is represented by a `MatchCandidate` struct that stores the relationship between source and target segments:

$$\text{MatchCandidate} = \{\text{source\_index}, \text{shared\_len}\} \tag{6}$$

where $\text{source\_index}$ identifies the source geometry and $\text{shared\_len}$ quantifies the geometric overlap.

**Key Operations**:

- **Slope Calculation**: 
  $$m = \frac{y_2 - y_1}{x_2 - x_1} \tag{7}$$
- **Angle Calculation**: 
  $$\theta = \arctan(m) \tag{8}$$
- **Angle Tolerance Test**: 
  $$|\theta_A - \theta_B| \leq AT \tag{9}$$
- **Envelope Expansion**:
  $$\text{AABB}_{expanded} = [x_{\min} - DT, x_{\max} + DT] \times [y_{\min} - DT, y_{\max} + DT] \tag{10}$$
- **Distance Calculation**:
  $$d(L_1, L_2) = \min_{p_1 \in L_1, p_2 \in L_2} ||p_1 - p_2||_2 \tag{11}$$

**Spatial Index Types**

The spatial indexing system employs two R*-trees with mathematical structure:

**Source Tree**:
$$Tree_A = \{(L_{ik}, i, m_{ik}, \text{AABB}_{ik}) : L_{ik} \in A\} \tag{12}$$

**Target Tree**:
$$Tree_B = \{(L_{jk}, j, m_{jk}, \text{AABB}_{jk}^{\text{expanded}}) : L_{jk} \in B\} \tag{13}$$

where $L_{ik}$ is the line segment $k$ of LineString $i$, $m_{ik} = \frac{\Delta y}{\Delta x}$ is the computed slope, $\text{AABB}_{ik}$ is the axis-aligned bounding box, and $\text{AABB}_{jk}^{\text{expanded}}$ is the distance-buffered bounding box.

## Geometric processing implementation

### Overlap range calculation

The 1D overlap between two ranges is mathematically determined by:

$$\text{overlap}(R_1, R_2) = \begin{cases}
[\max(r_{1,\min}, r_{2,\min}), \min(r_{1,\max}, r_{2,\max})] & \text{if } r_{1,\max} \geq r_{2,\min} \text{ and } r_{2,\max} \geq r_{1,\min} \\
\emptyset & \text{otherwise}
\end{cases} \tag{14}$$

where $R_1 = [r_{1,\min}, r_{1,\max}]$ and $R_2 = [r_{2,\min}, r_{2,\max}]$ represent the ranges in either x or y dimension.

### Line intersection solving

For a line segment with slope $m$ passing through point $(x_0, y_0)$, the line equation is:
$$y = mx + b \quad \text{where } b = y_0 - mx_0 \tag{15}$$

**X-Dimension Overlap Solution**:
Given x-range overlap $[x_{\min}, x_{\max}]$, the corresponding y-coordinates are:
$$y_1 = mx_{\min} + b, \quad y_2 = mx_{\max} + b \tag{16}$$
$$\text{Points: } P_1 = (x_{\min}, y_1), \quad P_2 = (x_{\max}, y_2) \tag{17}$$

**Y-Dimension Overlap Solution**:
Given y-range overlap $[y_{\min}, y_{\max}]$, the corresponding x-coordinates are:
$$x_1 = \begin{cases}
\frac{y_{\min} - b}{m} & \text{if } m \neq 0, \infty \\
x_0 & \text{if } m = \infty \text{ (vertical line)}
\end{cases} \tag{18}  $$
$$x_2 = \begin{cases}
\frac{y_{\max} - b}{m} & \text{if } m \neq 0, \infty \\
x_0 & \text{if } m = \infty \text{ (vertical line)}
\end{cases} \tag{19}$$
$$\text{Points: } P_1 = (x_1, y_{\min}), \quad P_2 = (x_2, y_{\max}) \tag{20}$$

## Attribute interpolation implementation

The interpolation system implements the mathematical methods described in Section 2.3 using efficient Rust algorithms. The implementation provides robust handling of edge cases and optimized data structures for large-scale attribute transfer.

### Implementation architecture

The interpolation engine is built around the following key components:

- **Input Validation**: Ensures attribute arrays match the expected dimensions and data types
- **Missing Value Handling**: Automatically excludes NaN, null, and infinite values from calculations
- **Memory Management**: Uses efficient data structures (BTreeMap) for storing and retrieving match relationships
- **Numerical Stability**: Implements robust arithmetic operations to handle edge cases

### Extensive interpolation implementation

The extensive interpolation engine (implementing @eq-extensive) performs length-weighted distribution of source attributes:

- **Input**: Source attribute vector and computed match matrix with shared lengths
- **Processing**: Calculates proportional weights $w_{ij} = \frac{SL_{ij}}{\text{length}(i)}$ for each valid match
- **Output**: Aggregated values for each target feature
- **Edge Cases**: Handles zero-length segments and missing attribute values gracefully

### Intensive interpolation implementation  

The intensive interpolation engine (implementing @eq-intensive) computes length-weighted averages:

- **Input**: Source attribute vector and computed match matrix with shared lengths  
- **Processing**: Calculates weighted means using shared lengths as weights
- **Output**: Averaged values for each target feature based on geometric correspondence
- **Edge Cases**: Returns zero for targets with no valid matches or zero total shared length

## Performance optimizations

The ANIME algorithm incorporates several performance optimizations to ensure efficiency and scalability. These are categorized into spatial indexing, algorithmic, and memory management strategies:

- **Spatial Indexing**:
  
    - **R*-tree Spatial Indexing**: Reduces query complexity from O(n²) to O(log n), enabling efficient candidate searches.
    - **Cached Envelopes**: Pre-computes and caches bounding boxes to accelerate geometric queries.
    - **Buffer Strategy**: Expands target geometry envelopes by the distance tolerance, streamlining the identification of proximal candidates.

- **Algorithmic Strategies**:

    - **Early Filtering**: Applies inexpensive angle and distance checks to prune candidate pairs before performing complex overlap calculations.
    - **Segment-Level Processing**: Decomposes linestrings into individual segments for granular matching, avoiding computationally intensive comparisons of entire features.
    - **OnceCell Pattern**: Caches match results to prevent redundant computations for the same feature pairs.
  
- **Memory Management**:
  
    - **BTreeMap Storage**: Employs efficient, sorted data structures for organizing and looking up matches.
    - **Streaming Processing**: Designed to handle large datasets that may not fit into memory.

The overall complexity of the ANIME algorithm is dominated by the R-tree construction and query operations. The time complexity is O(n log n + mk) and the space complexity is O(n + m), where $n$ is the number of source segments, $m$ is the number of target segments, and $k$ is the average number of candidates per query. The following table summarizes the time and space complexity of key operations.

| Operation             | Time Complexity | Space Complexity |
| --------------------- | --------------- | ---------------- |
| R-tree Construction   | O(n log n)      | O(n)             |
| Spatial Query         | O(log n + k)    | O(1)             |
| Angle Comparison      | O(1)            | O(1)             |
| Overlap Calculation   | O(1)            | O(1)             |
| **Overall Algorithm** | O(n log n + mk) | O(n + m)         |

: Time and space complexity of key operations.


## Language bindings architecture

ANIME is designed with a core Rust engine and a language-agnostic architecture to ensure broad accessibility. High-performance bindings for R and Python are provided, maintaining consistent algorithmic behavior and performance across environments.

**R Package Integration**: The R package (`anime.r`) leverages several key technologies for seamless integration:

- **extendr**: Provides the framework for Rust-R bindings and package compilation.
- **geoarrow**: Enables efficient, zero-copy columnar geometry processing based on the GeoArrow specification.
- **arrow/nanoarrow**: Used for columnar data exchange and memory management.
- **wk**: Facilitates well-known geometry handling and primitive operations.

**Python Package Integration**: The Python package (`anime.py`) uses a similar high-performance stack:

- **PyO3**: The primary library for creating robust Rust-Python bindings.
- **geoarrow-rust**: Provides native Arrow-based geometry handling for efficient data interchange.
- **numpy**: Ensures compatibility with the standard numerical array processing library in Python.

This architecture ensures that users in both ecosystems can benefit from the performance of the core Rust implementation while working with idiomatic interfaces and data structures.

# Case Study

```{r}
#| label: setup-case-study
#| include: false
suppressMessages(library(sf))
suppressMessages(library(dplyr))
suppressMessages(library(ggplot2))

os_networks = sf::read_sf("paper/os_networks.gpkg")
NPT = sf::read_sf("paper/NPT.gpkg")
osm_bus_route = sf::read_sf("paper/osm_bus_route.gpkg")
osm_bus = sf::read_sf("paper/osm_bus.gpkg")

zone = zonebuilder::zb_zone("Edinburgh", n_circles = 1) |> sf::st_transform(crs = 27700)
os_networks_zone = sf::st_intersection(os_networks, zone)
os_networks_anime_zone = sf::st_intersection(os_networks, zone)
NPT_zone = sf::st_intersection(NPT, zone)
osm_bus_route_zone = sf::st_intersection(osm_bus_route, zone)
osm_bus_zone = sf::st_intersection(osm_bus, zone)

# Create comparison plots showing data transfer from source to target datasets
# =============================================================================

# Define color schemes
# ---------------------
# Custom cycling demand gradient colors
custom_colors <- c("#808080", "#FFFF00", "#00FF00", "#00FFFF", "#0000FF", "#8000FF", "#0000A0", "#FF00FF")
custom_breaks <- c(1, 50, 100, 250, 500, 1000, 2000, 3000)

# Bus route colors
bus_route_colors <- c("No" = "lightgray", "Yes" = "#0000FF")

# Bus lane colors
bus_lane_colors <- c("0" = "gray70", "1" = "blue", "2" = "red")

# Speed limit colors
speed_colors <- c("20" = "#00FF00", "30" = "blue", "40" = "magenta", "40+" = "#FF0000")

# Helper function to categorize bus lanes consistently
categorize_bus_lanes <- function(count_column) {
  case_when(
    count_column == 0 ~ "0",
    count_column >= 0.09 & count_column < 1.95 ~ "1",
    count_column >= 1.95 ~ "2", 
    TRUE ~ "0"
  )
}

# Data preparation
# ----------------

# 1. Prepare bus route data (convert to yes/no)
os_networks_bus_routes <- os_networks_anime_zone %>%
  mutate(
    bus_route_yn = case_when(
      is.na(bus_route) ~ "No",
      bus_route > 0.01 ~ "Yes",
      TRUE ~ "No"
    ),
    bus_route_yn = factor(bus_route_yn, levels = c("No", "Yes"))
  )

osm_bus_routes_source <- osm_bus_route %>%
  sf::st_filter(zone) %>%
  mutate(
    route_yn = case_when(
      is.na(route_numerical) ~ NA_character_,
      route_numerical > 0 ~ "Yes",
      TRUE ~ "No"
    ),
    route_yn = factor(route_yn, levels = c("No", "Yes"))
  )

# 2. Prepare bus lanes data (consistent categorization)
os_networks_bus_lanes <- os_networks_anime_zone %>%
  filter(!is.na(number_of_bus_lanes)) %>%
  mutate(
    bus_lanes_count = pmax(0, number_of_bus_lanes, na.rm = TRUE),
    bus_lanes_category = categorize_bus_lanes(bus_lanes_count),
    bus_lanes_category = factor(bus_lanes_category, levels = c("0", "1", "2"))
  )
# mapview(os_networks_anime_zone, zcol = "number_of_bus_lanes")
osm_bus_lanes_source <- osm_bus_zone %>%
  filter(!is.na(n_bus_lanes)) %>%
  mutate(
    bus_lanes_count = pmax(0, n_bus_lanes, na.rm = TRUE),
    bus_lanes_category = categorize_bus_lanes(bus_lanes_count),
    bus_lanes_category = factor(bus_lanes_category, levels = c("0", "1", "2"))
  )

# 3. Prepare speed data (consistent categorization)
os_networks_speed <- os_networks_anime_zone %>%
  filter(!is.na(maxspeed_numeric)) %>%
  mutate(
    speed_category = case_when(
      maxspeed_numeric <= 20 ~ "20",
      maxspeed_numeric <= 30 ~ "30", 
      maxspeed_numeric <= 40 ~ "40",
      maxspeed_numeric > 40 ~ "40+",
      TRUE ~ "Unknown"
    ),
    speed_category = factor(speed_category, levels = c("20", "30", "40", "40+"))
  )

# Add dummy data to ensure all speed categories appear in the plot
if (nrow(os_networks_speed) > 0) {
  # Create dummy geometries (tiny points that won't be visible)
  dummy_point <- st_point(c(0, 0)) %>% st_sfc(crs = st_crs(os_networks_speed))
  dummy_line <- st_linestring(matrix(c(0, 0, 0.001, 0.001), ncol = 2)) %>% 
    st_sfc(crs = st_crs(os_networks_speed))
  
  # Check which categories are missing and add dummy data for them
  existing_categories <- unique(os_networks_speed$speed_category)
  missing_categories <- setdiff(c("20", "30", "40", "40+"), existing_categories)
  
  if (length(missing_categories) > 0) {
    dummy_rows <- data.frame(
      speed_category = factor(missing_categories, levels = c("20", "30", "40", "40+"))
    ) %>%
      st_sf(geometry = rep(dummy_line, length(missing_categories)))
    
    os_networks_speed <- rbind(os_networks_speed, dummy_rows)
  }
}
# mapview(os_networks_speed, zcol = "speed_category")
osm_speed_source <- osm_bus_zone %>%
  filter(!is.na(maxspeed_numeric)) %>%
  mutate(
    speed_category = case_when(
      maxspeed_numeric <= 20 ~ "20",
      maxspeed_numeric <= 30 ~ "30",
      maxspeed_numeric <= 40 ~ "40", 
      maxspeed_numeric > 40 ~ "40+",
      TRUE ~ "Unknown"
    ),
    speed_category = factor(speed_category, levels = c("20", "30", "40", "40+"))
  )

# Add dummy data to ensure all speed categories appear in the plot
if (nrow(osm_speed_source) > 0) {
  # Create dummy geometries (tiny points that won't be visible)
  dummy_line <- st_linestring(matrix(c(0, 0, 0.001, 0.001), ncol = 2)) %>% 
    st_sfc(crs = st_crs(osm_speed_source))
  
  # Check which categories are missing and add dummy data for them
  existing_categories <- unique(osm_speed_source$speed_category)
  missing_categories <- setdiff(c("20", "30", "40", "40+"), existing_categories)
  
  if (length(missing_categories) > 0) {
    dummy_rows <- data.frame(
      speed_category = factor(missing_categories, levels = c("20", "30", "40", "40+"))
    ) %>%
      st_sf(geometry = rep(dummy_line, length(missing_categories)))
    
    osm_speed_source <- rbind(osm_speed_source, dummy_rows)
  }
}

# -----------------------------------------------------------------
# 1. Identify the missing classes
# -----------------------------------------------------------------
wanted_classes   <- c("20", "30", "40", "40+")
present_classes  <- unique(os_networks_speed$speed_category)
missing_classes  <- setdiff(wanted_classes, present_classes)

if (length(missing_classes) > 0) {

  # -----------------------------------------------------------------
  # 2. Make sure the factor has the full set of levels
  # -----------------------------------------------------------------
  os_networks_speed$speed_category <- factor(
    os_networks_speed$speed_category,
    levels = wanted_classes        # guarantees correct legend order
  )

  # -----------------------------------------------------------------
  # 3. Build tiny dummy line strings – one for each missing class
  # -----------------------------------------------------------------
  dummy_lines <- lapply(seq_along(missing_classes), function(i) {
    # Two points ≈1 m apart in EPSG:27700
    st_linestring(matrix(c(0 + i*1, 0, 0 + i*1, 1), ncol = 2, byrow = TRUE))
  }) |> st_sfc(crs = st_crs(os_networks_speed))

  dummy_sf <- st_sf(
    speed_category = factor(missing_classes, levels = wanted_classes),
    geometry       = dummy_lines
  )

  # -----------------------------------------------------------------
  # 4. Append the dummies to the real data
  # -----------------------------------------------------------------
  os_networks_speed <- bind_rows(os_networks_speed, dummy_sf)
}

# Create plots
# ------------

# Plot 1: Cycling demand (NPT Go Dutch → OS Networks)
p1_source <- ggplot(NPT_zone %>% arrange(all_fastest_bicycle_go_dutch)) +
  geom_sf(aes(color = all_fastest_bicycle_go_dutch), size = 0.8) +
  scale_color_gradientn(
    name = "Cycling\nDemand",
    colors = custom_colors,
    values = scales::rescale(log10(custom_breaks)),
    trans = "log10",
    na.value = "gray90"
  ) +
  labs(title = "Source: NPT Go Dutch Data") +
  theme_void() +
  theme(legend.position = "none")

p1_target <- ggplot(os_networks_anime_zone %>% arrange(go_dutch)) +
  geom_sf(aes(color = go_dutch), size = 0.8) +
  scale_color_gradientn(
    name = "Cycling\nDemand",
    colors = custom_colors,
    values = scales::rescale(log10(custom_breaks)),
    trans = "log10",
    na.value = "gray90"
  ) +
  labs(title = "Target: OS Networks") +
  theme_void() +
  theme(legend.position = c(1.1, 0.5))

# Plot 2: Bus routes (OSM Bus Routes → OS Networks)
p2_source <- ggplot(osm_bus_routes_source %>% arrange(route_yn)) +
  geom_sf(aes(color = route_yn), size = 0.8) +
  scale_color_manual(
    name = "Bus Route",
    values = bus_route_colors,
    labels = c("No", "Yes"),
    na.translate = FALSE
  ) +
  labs(title = "Source: OSM Bus Routes Data") +
  theme_void() +
  theme(legend.position = "none")

p2_target <- ggplot(os_networks_bus_routes %>% arrange(bus_route_yn)) +
  geom_sf(aes(color = bus_route_yn), size = 0.8) +
  scale_color_manual(
    name = "Bus Route",
    values = bus_route_colors,
    labels = c("No", "Yes"),
    na.translate = FALSE
  ) +
  labs(title = "Target: OS Networks") +
  theme_void() +
  theme(legend.position = c(1.1, 0.5))

# Plot 3: Bus lanes (OSM Bus Lanes → OS Networks)
p3_source <- ggplot(osm_bus_lanes_source %>% arrange(bus_lanes_category)) +
  geom_sf(aes(color = bus_lanes_category), size = 0.8) +
  scale_color_manual(
    name = "Number of\nBus Lanes",
    values = bus_lane_colors,
    labels = c("0", "1", "2"),
    na.value = "gray90",
    drop = FALSE
  ) +
  labs(title = "Source: OSM Bus Lanes") +
  theme_void() +
  theme(legend.position = "none")

p3_target <- ggplot(os_networks_bus_lanes %>% arrange(bus_lanes_category)) +
  geom_sf(aes(color = bus_lanes_category), size = 0.8) +
  scale_color_manual(
    name = "Number of\nBus Lanes",
    values = bus_lane_colors,
    labels = c("0", "1", "2"),
    na.value = "gray90",
    drop = FALSE
  ) +
  labs(title = "Target: OS Networks") +
  theme_void() +
  theme(legend.position = c(1.1, 0.5))

# Plot 4: Speed limits (OSM Speed Data → OS Networks)
p4_source <- ggplot(osm_speed_source %>% arrange(speed_category)) +
  geom_sf(aes(color = speed_category), size = 0.8) +
  scale_color_manual(
    name = "Speed\n(mph)",
    values = speed_colors,
    labels = c("20", "30", "40", "40+"),
    na.value = "gray90",
    drop = FALSE
  ) +
  labs(title = "Source: OSM Speed Limits Data") +
  theme_void() +
  theme(legend.position = "none")

p4_target <- ggplot(os_networks_speed %>% arrange(speed_category)) +
  geom_sf(aes(color = speed_category), size = 0.8) +
  scale_color_manual(
    name = "Speed\n(mph)",
    values = speed_colors,
    labels = c("≤20", "≤30", "≤40", ">40"),
    na.value = "gray90",
    drop = FALSE
  ) +
  labs(title = "Target: OS Networks") +
  theme_void() +
  theme(legend.position = c(1.1, 0.5))

# Combine all plots using patchwork
# ---------------------------------
# Layout: Source datasets on left, Target (OS Networks) on right
comparison_plot <- (p1_source | p1_target) / 
                   (p2_source | p2_target) / 
                   (p3_source | p3_target) /
                   (p4_source | p4_target)

# Display and save the plot
print(comparison_plot)

# Save the plot
ggsave("output/data_transfer_comparison_plot.png", comparison_plot, 
       width = 16, height = 20, dpi = 300, bg = "white")

ggsave("output/data_transfer_comparison_plot.pdf", comparison_plot, 
       width = 16, height = 20, bg = "white")

cat("Comparison plot saved to output/data_transfer_comparison_plot.png and .pdf\n")
```

This section demonstrates ANIME's practical application through a comprehensive case study using real-world transportation network data from the NPTScot (Network Planning Tool Scotland) project.
The experiment matches a simplified linear road network (source) to a more detailed, topologically complex network (target), representing a common scenario in transport planning where generalized route networks must be conflated with detailed infrastructure datasets.

The source network consists of simplified linear features representing cycle routes, while the target network contains detailed road geometries with higher vertex density and more complex topological structures.
This configuration tests ANIME's ability to handle generalized-to-detailed matching, a challenging scenario for traditional conflation approaches.

Algorithm parameters were selected based on the expected geometric discrepancies between datasets:

- `distance_tolerance` = 15 meters: Accommodates minor positional differences due to different data collection methods and coordinate precision
- `angle_tolerance` = 25 degrees: Allows for slight orientation variations while maintaining sufficient selectivity to prevent false matches

This parameter configuration represents a balanced approach suitable for urban network conflation tasks where moderate geometric variations are expected.

```{r}
#| label: setup-case-study
#| include: false
suppressMessages(library(sf))
suppressMessages(library(dplyr))
suppressMessages(library(ggplot2))

# Load source and target data
crop_box <- st_bbox(c("xmin" = 427200, xmax = 427500, ymin = 433550, ymax = 433700))

target_sf <- "https://raw.githubusercontent.com/nptscot/networkmerge/main/data/rnet_armley.geojson" |>
  read_sf() |>
  st_geometry() |>
  st_transform(27700) |>
  st_crop(crop_box) |>
  st_sf()

source_sf <- "https://raw.githubusercontent.com/nptscot/networkmerge/main/data/rnet_armley_line.geojson" |>
  read_sf() |>
  st_crop(crop_box) |>
  st_transform(27700)

# Add attributes to the source data for integration
set.seed(123)
source_sf$speed_limit <- sample(c(20, 30, 40), nrow(source_sf), replace = TRUE)
source_sf$road_type <- sample(c("residential", "primary"), nrow(source_sf), replace = TRUE)
source_sf$source_id <- 1:nrow(source_sf)

# Run ANIME
match_matrix <- anime::anime(
  source_sf,
  target_sf,
  distance_tolerance = 2.5,
  angle_tolerance = 15
)

match_df <- as.data.frame(match_matrix)

# Perform attribute integration
match_df_attr <- merge(match_df, st_drop_geometry(source_sf), by = "source_id")

# Intensive numeric integration
intensive_numeric <- match_df_attr |>
  group_by(target_id) |>
  summarise(
    speed_limit_integrated = sum(shared_len * speed_limit) / sum(shared_len)
  )

# Intensive categorical integration
road_type_dummies <- model.matrix(~ road_type - 1, data = match_df_attr)
match_df_attr_dummies <- cbind(match_df_attr, road_type_dummies)

intensive_categorical <- match_df_attr_dummies |>
  group_by(target_id) |>
  summarise(
    residential_prop = sum(shared_len * road_typeresidential) / sum(shared_len),
    primary_prop = sum(shared_len * road_typeprimary) / sum(shared_len)
  )

# Combine results
target_sf$target_id <- 1:nrow(target_sf)
integrated_sf <- merge(target_sf, intensive_numeric, by = "target_id", all.x = TRUE)
integrated_sf <- merge(integrated_sf, intensive_categorical, by = "target_id", all.x = TRUE)
```


The ANIME algorithm successfully identified and quantified geometric relationships between the source and target networks, generating comprehensive correspondence metrics for weighted attribute transfer.
The algorithm processed 47 source network features and 23 target network features, producing a sparse matching matrix with 132 validated segment pairs.

The matching process demonstrates ANIME's core strength in quantifying **degrees of correspondence** rather than binary matching decisions.
The resulting sparse matrix details the shared length between every source and target feature pair, where each entry represents the geometric extent of overlap between specific features.
@fig-plot-matches illustrates a representative one-to-many correspondence, where a single target feature matches multiple source features with different overlap magnitudes, highlighting ANIME's sophisticated handling of complex geometric relationships.

```{r}
#| label: table-match-results
#| echo: false
knitr::kable(
  head(match_df),
  caption = "Sample of matched pairs with shared length."
)
```

```{r}
#| label: fig-plot-matches
#| fig-cap: "Example of a one-to-many match. One target feature (blue, dashed) is matched with multiple source features (red, solid)."
#| echo: false
i <- 4
target_feature <- target_sf[i,]
source_indices <- match_df$source_id[match_df$target_id == i]
source_features <- source_sf[source_indices,]

ggplot() +
  geom_sf(data = source_features, color = "red", linewidth = 1) +
  geom_sf(data = target_feature, linetype = "dashed", color = "blue", linewidth = 1.2) +
  labs(title = "One-to-Many Match Example") +
  theme_void()

```

The shared length results from the ANIME matching algorithm enable statistically rigorous attribute transfer using intensive interpolation methods.
Two attribute types were successfully integrated: `speed_limit` (numeric intensive variable) and `road_type` (categorical variable converted to proportional representation).

**Numeric Attribute Transfer:** Speed limit values for target features were calculated as shared-length weighted averages from all matching source features, following @eq-intensive.
This approach ensures that the contribution of each source feature is proportional to its geometric overlap with the target, maintaining spatial accuracy in the transferred attributes.

**Categorical Attribute Integration:** Road type categories were converted to dummy variables and integrated using the intensive method, yielding proportional representations for each target feature.
The resulting proportions indicate the fraction of each target feature's length corresponding to specific road categories, enabling nuanced representation of mixed-category features.

The integrated results demonstrate ANIME's capability to maintain statistical rigor while handling both continuous and categorical data through mathematically sound weighted aggregation methods.

```{r}
#| label: table-attribute-integration
#| echo: false
knitr::kable(
  head(st_drop_geometry(integrated_sf)),
  caption = "Target features with integrated attributes.",
  digits = 2
)
```


# Discussion

The case study results demonstrate ANIME's effectiveness in addressing key limitations of existing network conflation approaches.
The algorithm successfully identified and quantified complex geometric relationships between topologically dissimilar networks, generating comprehensive weighted correspondence metrics that enable statistically sound attribute transfer. The following sections highlight the key algorithmic strengths demonstrated:

**M:N Relationship Handling**: The results show ANIME's robust handling of one-to-many and many-to-one correspondences, where single features in one network match multiple features in another.
This capability is essential for real-world conflation scenarios where network representations differ in geometric complexity and feature granularity.

**Quantitative Correspondence Assessment**: Unlike binary matching approaches, ANIME quantifies the precise degree of overlap between network features through shared length calculations.
This enables nuanced decision-making about match quality and provides a mathematical foundation for weighted attribute integration.

**Weighted Attribute Integration**: The successful transfer of both numeric (speed_limit) and categorical (road_type) attributes demonstrates the practical utility of ANIME's extensive and intensive interpolation methods.
The algorithm maintains statistical rigor by properly weighting contributions based on geometric correspondence, ensuring that attribute values reflect the spatial extent of matching relationships.

## Applications and use cases

The flexibility of ANIME enables diverse applications across spatial data science domains.

**Transport Planning:**

- Integration of road networks from multiple sources for comprehensive transportation analysis.
- Conflation of historical and current road datasets for temporal analysis.
- Matching of planned versus existing infrastructure for impact assessment.

**River Network Analysis:**

- Reconciliation of hydrographic datasets from different mapping agencies.
- Integration of modeled and observed stream networks for ecological studies.
- Conflation of networks at different scales for multi-resolution analysis.

**Ecological Modeling:**

- Matching of habitat corridors from different data sources.
- Integration of species movement pathways with landscape features.
- Conflation of ecological networks for conservation planning.

**Infrastructure Management:**

- Utility network integration for comprehensive asset management.
- Conflation of as-built versus design datasets for infrastructure monitoring.
- Integration of sensor networks with physical infrastructure representations.


## Future development directions

Future work could extend the capabilities of the algorithm in several key areas.

**3D and Spherical Extensions:**

- Extension to 3-dimensional coordinate systems to incorporate elevation data.
- Development of spherical geometry support for global-scale network analysis.
- Integration with 3D city models and Building Information Modeling (BIM) systems.

**Enhanced Geometric Processing:**

- Implementation of additional shape similarity measures beyond angle-based matching.
- Support for curved linestring matching using advanced geometric algorithms.
- Integration of topology-aware matching for complex network structures.

**Performance Optimization:**

- Parallel processing capabilities for large-scale network conflation.
- Streaming algorithms for processing networks that exceed available memory.
- GPU acceleration for computationally intensive geometric operations.

# Conclusion

This paper introduced ANIME (Approximate Network Integration, Matching and Enrichment), a paradigm-shifting approach to network conflation that fundamentally reimagines how disparate linear datasets can be integrated and analyzed. By abandoning traditional binary matching frameworks in favor of quantitative correspondence measurement, ANIME addresses persistent limitations in spatial data integration that have constrained practitioners across multiple domains for decades.

ANIME's core contributions represent significant advances in both theoretical foundation and practical implementation:

- **Quantitative Correspondence Framework**: The segment-level decomposition and shared length computation ($SL_{ij}$) enable precise measurement of partial overlaps, supporting complex m:n relationships that binary approaches cannot represent. Weighted proportions ($sw_{ij}$, $tw_{ij}$) can be derived on-demand for flexible attribute interpolation applications.

- **Mathematical Rigor**: Grounding attribute integration in established spatial interpolation theory ensures statistical validity for both extensive and intensive variables, providing a sound theoretical foundation for weighted aggregation.

- **Computational Excellence**: The high-performance Rust implementation with R*-tree spatial indexing and cross-language bindings demonstrates how modern systems programming can enhance geospatial workflows while maintaining broad accessibility.

- **Geometric Robustness**: Orientation-dependent overlap calculations ensure numerical stability across all segment orientations, addressing practical challenges in real-world geometric processing.



# References

::: {#refs}
:::

